import{_ as i,c as a,o as n,ae as e}from"./chunks/framework.JvnCEULl.js";const t="/portfolio-site/assets/prompt_image_mapping.DvA_ub5B.jpg",r="/portfolio-site/assets/sender_reciever_sequence.CkzOdxmD.jpg",h="/portfolio-site/assets/surf_images.CV4KsSJN.png",y=JSON.parse('{"title":"Generative Steganography System","description":"","frontmatter":{"sidebar":false},"headers":[],"relativePath":"projects/gsim.md","filePath":"projects/gsim.md"}'),l={name:"projects/gsim.md"};function p(k,s,o,g,d,E){return n(),a("div",null,s[0]||(s[0]=[e('<h1 id="generative-steganography-system" tabindex="-1">Generative Steganography System <a class="header-anchor" href="#generative-steganography-system" aria-label="Permalink to &quot;Generative Steganography System&quot;">​</a></h1><p><strong>Team Members:</strong> Ryan Farley, Courtney Dickenson, Ariel Ong, Tushar Wani<br><strong>Role:</strong> Feature Extraction, SURF Implementation, Parallel Processing<br><strong>Tools:</strong> Python, Google Colab, SDXL Turbo, OpenCV, Fractional Fourier Chebyshev Moments (FrCHFMs)<br><strong>Repository:</strong> <a href="https://github.com/R-D-Team-7/GSIM-Backend" target="_blank" rel="noreferrer">GitHub - GSIM-Backend</a></p><hr><h2 id="project-overview" tabindex="-1">Project Overview <a class="header-anchor" href="#project-overview" aria-label="Permalink to &quot;Project Overview&quot;">​</a></h2><p>This project explores <strong>coverless steganography</strong> – embedding secret messages in <strong>AI-generated images</strong> without modifying the carrier medium. By leveraging <strong>robust feature extraction</strong> methods like <strong>SURF descriptors</strong> and <strong>FrCHFMs</strong>, the system enhances resilience against <strong>geometric attacks</strong> (rotation, scaling, cropping).</p><h3 id="key-focus-areas" tabindex="-1">Key Focus Areas: <a class="header-anchor" href="#key-focus-areas" aria-label="Permalink to &quot;Key Focus Areas:&quot;">​</a></h3><ul><li><strong>AI-Generated Image Steganography</strong> – No alterations to the image, ensuring covert communication.</li><li><strong>Geometric Attack Resistance</strong> – Secure against transformations that typically break traditional steganography.</li><li><strong>High-Capacity Encoding</strong> – Messages up to <strong>576 bits</strong> concealed efficiently across image sets.</li></ul><p><img src="'+t+'" alt="Image Prompt Mapping"></p><hr><h2 id="key-contributions" tabindex="-1">Key Contributions <a class="header-anchor" href="#key-contributions" aria-label="Permalink to &quot;Key Contributions&quot;">​</a></h2><ul><li><strong>Engineered a complete steganography pipeline</strong> to encode and extract messages seamlessly.</li><li><strong>Implemented SURF-based feature extraction</strong> to withstand geometric transformations.</li><li><strong>Optimized for speed</strong> by parallelizing keypoint detection with Python&#39;s <code>ThreadPoolExecutor</code>.</li><li><strong>Developed amplitude mapping algorithms</strong> for encoding binary sequences into generated images.</li></ul><hr><h2 id="system-architecture" tabindex="-1">System Architecture <a class="header-anchor" href="#system-architecture" aria-label="Permalink to &quot;System Architecture&quot;">​</a></h2><h3 id="workflow-breakdown" tabindex="-1">Workflow Breakdown: <a class="header-anchor" href="#workflow-breakdown" aria-label="Permalink to &quot;Workflow Breakdown:&quot;">​</a></h3><ol><li><strong>Secret Message Input</strong> – Users input the message to be hidden.</li><li><strong>Binary Conversion</strong> – Message is transformed into binary segments.</li><li><strong>AI Prompt Generation</strong> – Images are created using AI models for each binary segment.</li><li><strong>Feature Extraction (SURF + FrCHFM)</strong> – Features encode binary values into images.</li><li><strong>Stego Image Assembly &amp; Transfer</strong> – Encoded images are bundled and sent.</li><li><strong>Message Extraction at Receiver End</strong> – The receiver extracts the hidden message by regenerating image features.</li></ol><p><img src="'+r+`" alt="Sender Recieve Sequence"></p><hr><h2 id="code-highlights" tabindex="-1">Code Highlights <a class="header-anchor" href="#code-highlights" aria-label="Permalink to &quot;Code Highlights&quot;">​</a></h2><h3 id="_1-surf-based-feature-extraction" tabindex="-1">1. SURF-Based Feature Extraction <a class="header-anchor" href="#_1-surf-based-feature-extraction" aria-label="Permalink to &quot;1. SURF-Based Feature Extraction&quot;">​</a></h3><p>One of the core components of our Generative Steganography System (GSIM) is the <strong>SURF-based feature extraction</strong>. This method enhances the system&#39;s resilience against geometric attacks by detecting keypoints robustly across different image scales.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># SURF feature extraction for keypoint detection and description</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> calculate_surf_descriptors</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(image, threshold</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, num_scales</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, grid_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, binary_threshold</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, num_top_keypoints</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    gray_image </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cv2.cvtColor(image, cv2.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">COLOR_BGR2GRAY</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    pyramid </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> build_image_pyramid(gray_image, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">num_scales</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">num_scales)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    all_keypoints </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> []</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scale_idx, scaled_image </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> enumerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(pyramid):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        scale_factor </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1.2</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> **</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scale_idx</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        integral_image </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> compute_integral_image(scaled_image)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        keypoints </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> detect_keypoints(integral_image, threshold, scaled_image, scale_factor)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        all_keypoints.extend([(kp[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scale_factor, kp[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scale_factor, kp[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], scale_idx) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> kp </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> keypoints])</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    keypoints </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> non_max_suppression(all_keypoints, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">grid_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">grid_size)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    sorted_keypoints </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> sorted</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(keypoints, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=lambda</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x: x[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">reverse</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    points2f </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.array([(k[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], k[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> k </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sorted_keypoints], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">np.float32)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    keypoints_cv2 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cv2.KeyPoint_convert(points2f, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    descriptors </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> extract_descriptors_parallel(keypoints_cv2, gray_image)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    binary_sequence </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> generate_binary_sequence_from_descriptors(descriptors, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">threshold</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">binary_threshold)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> keypoints_cv2, descriptors, binary_sequence</span></span></code></pre></div><p><strong>Key Benefits:</strong></p><ul><li><strong>Robust against transformations</strong> – Scaling, rotation, and slight cropping.</li><li><strong>Parallelized execution</strong> – Faster processing for large datasets.</li></ul><p><img src="`+h+`" alt="SURF Keypoints"></p><hr><h3 id="_2-fractional-fourier-chebyshev-moments-frchfms" tabindex="-1">2. Fractional Fourier Chebyshev Moments (FrCHFMs) <a class="header-anchor" href="#_2-fractional-fourier-chebyshev-moments-frchfms" aria-label="Permalink to &quot;2. Fractional Fourier Chebyshev Moments (FrCHFMs)&quot;">​</a></h3><p>To enhance robustness against geometric distortions, we use <strong>Fractional Chebyshev-Fourier Moments (FrCHFMs)</strong>, computed efficiently on the GPU. This ensures stability under scaling and rotation.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Compute FrCHFMs using GPU acceleration</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> compute_frchfm_gpu</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(image, max_degree, t):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    polar_image, r, theta </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> convert_to_polar(image)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    polar_image_gpu </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cp.array(polar_image)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    r_gpu </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cp.array(r)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    theta_gpu </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cp.array(theta)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    F_image </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cp.fft.fftshift(cp.fft.fft2(polar_image_gpu))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    frchfm_gpu </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cp.zeros((max_degree </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> *</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> max_degree </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">cp.complex128)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    m_values </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cp.arange(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">max_degree, max_degree </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    angular_components </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cp.exp(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> *</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> m_values[:, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> theta_gpu)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> n </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(max_degree </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        Rtn_gpu </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> radial_basis_function_gpu(n, t, r_gpu)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        frchfm_gpu[n, :] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cp.sum(F_image </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Rtn_gpu </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> angular_components </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> r_gpu, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">axis</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cp.asnumpy(frchfm_gpu)</span></span></code></pre></div><p><strong>Key Benefits:</strong></p><ul><li><strong>Geometric invariance</strong> – Maintains stability across distortions.</li><li><strong>Polar coordinate mapping</strong> – Improves feature localization and precision.</li></ul><hr><h2 id="results" tabindex="-1">Results <a class="header-anchor" href="#results" aria-label="Permalink to &quot;Results&quot;">​</a></h2><ul><li><strong>PSNR:</strong> &gt; 38 dB – Ensuring nearly indistinguishable stego images.</li><li><strong>Extraction Accuracy:</strong> 100% across all test cases.</li><li><strong>Encoding Capacity:</strong> 8 bits per image, supporting 576 bits using 72 images.</li></ul><hr><h2 id="challenges-and-solutions" tabindex="-1">Challenges and Solutions <a class="header-anchor" href="#challenges-and-solutions" aria-label="Permalink to &quot;Challenges and Solutions&quot;">​</a></h2><h3 id="_1-keypoint-detection-instability" tabindex="-1">1. Keypoint Detection Instability <a class="header-anchor" href="#_1-keypoint-detection-instability" aria-label="Permalink to &quot;1. Keypoint Detection Instability&quot;">​</a></h3><ul><li><strong>Issue:</strong> Keypoints were inconsistently detected across transformed images.</li><li><strong>Fix:</strong> Optimized <strong>SURF descriptor thresholds</strong> and applied <strong>non-maximum suppression tuning</strong>.</li></ul><h3 id="_2-computational-overhead" tabindex="-1">2. Computational Overhead <a class="header-anchor" href="#_2-computational-overhead" aria-label="Permalink to &quot;2. Computational Overhead&quot;">​</a></h3><ul><li><strong>Issue:</strong> Processing delays due to image generation and feature extraction.</li><li><strong>Fix:</strong> Implemented <strong>parallel processing</strong> using <code>ThreadPoolExecutor</code>, reducing runtime by 40%.</li></ul><h3 id="_3-feature-drift-during-cropping" tabindex="-1">3. Feature Drift During Cropping <a class="header-anchor" href="#_3-feature-drift-during-cropping" aria-label="Permalink to &quot;3. Feature Drift During Cropping&quot;">​</a></h3><ul><li><strong>Issue:</strong> Cropping led to feature misalignment, affecting message extraction.</li><li><strong>Fix:</strong> Used <strong>FrCHFM amplitude mapping</strong> to ensure geometric invariance.</li></ul><hr><h2 id="future-enhancements" tabindex="-1">Future Enhancements <a class="header-anchor" href="#future-enhancements" aria-label="Permalink to &quot;Future Enhancements&quot;">​</a></h2><ul><li><strong>Automated parameter tuning</strong> for varying message sizes.</li><li><strong>Receiver simulation</strong> for end-to-end testing.</li><li><strong>Encrypted CLI messaging</strong> for secure peer-to-peer communication.</li></ul><hr><h2 id="key-takeaways" tabindex="-1">Key Takeaways <a class="header-anchor" href="#key-takeaways" aria-label="Permalink to &quot;Key Takeaways&quot;">​</a></h2><ul><li><strong>Innovative coverless steganography</strong> using AI-generated images and feature extraction.</li><li><strong>High resilience to geometric attacks</strong> – A leap forward in secure data embedding.</li><li><strong>Open-source commitment</strong> – Encouraging community collaboration and research growth.</li></ul><hr>`,48)]))}const u=i(l,[["render",p]]);export{y as __pageData,u as default};
