import{_ as i,c as a,o as e,ae as n}from"./chunks/framework.JvnCEULl.js";const d=JSON.parse('{"title":"Generative Steganography System","description":"","frontmatter":{},"headers":[],"relativePath":"gsim.md","filePath":"gsim.md"}'),t={name:"gsim.md"};function h(r,s,l,p,k,o){return e(),a("div",null,s[0]||(s[0]=[n(`<h1 id="generative-steganography-system" tabindex="-1">Generative Steganography System <a class="header-anchor" href="#generative-steganography-system" aria-label="Permalink to &quot;Generative Steganography System&quot;">​</a></h1><p><strong>Team Members:</strong> Ryan Farley, Courtney Dickenson, Ariel Ong, Tushar Wani<br><strong>Role:</strong> Feature Extraction, SURF Implementation, Parallel Processing<br><strong>Tools:</strong> Python, Google Colab, SDXL Turbo, OpenCV, Fractional Fourier Chebyshev Moments (FrCHFMs)<br><strong>Repository:</strong> <a href="https://github.com/R-D-Team-7/GSIM-Backend" target="_blank" rel="noreferrer">GitHub - GSIM-Backend</a></p><hr><h2 id="project-overview" tabindex="-1">Project Overview <a class="header-anchor" href="#project-overview" aria-label="Permalink to &quot;Project Overview&quot;">​</a></h2><p>This project explores <strong>coverless steganography</strong> – embedding secret messages in <strong>AI-generated images</strong> without modifying the carrier medium. By leveraging <strong>robust feature extraction</strong> methods like <strong>SURF descriptors</strong> and <strong>FrCHFMs</strong>, the system enhances resilience against <strong>geometric attacks</strong> (rotation, scaling, cropping).</p><h3 id="key-focus-areas" tabindex="-1">Key Focus Areas: <a class="header-anchor" href="#key-focus-areas" aria-label="Permalink to &quot;Key Focus Areas:&quot;">​</a></h3><ul><li><strong>AI-Generated Image Steganography</strong> – No alterations to the image, ensuring covert communication.</li><li><strong>Geometric Attack Resistance</strong> – Secure against transformations that typically break traditional steganography.</li><li><strong>High-Capacity Encoding</strong> – Messages up to <strong>576 bits</strong> concealed efficiently across image sets.</li></ul><hr><h2 id="key-contributions" tabindex="-1">Key Contributions <a class="header-anchor" href="#key-contributions" aria-label="Permalink to &quot;Key Contributions&quot;">​</a></h2><ul><li><strong>Engineered a complete steganography pipeline</strong> to encode and extract messages seamlessly.</li><li><strong>Implemented SURF-based feature extraction</strong> to withstand geometric transformations.</li><li><strong>Optimized for speed</strong> by parallelizing keypoint detection with Python&#39;s <code>ThreadPoolExecutor</code>.</li><li><strong>Developed amplitude mapping algorithms</strong> for encoding binary sequences into generated images.</li></ul><hr><h2 id="system-architecture" tabindex="-1">System Architecture <a class="header-anchor" href="#system-architecture" aria-label="Permalink to &quot;System Architecture&quot;">​</a></h2><p><strong>Workflow Breakdown:</strong></p><ol><li><strong>Secret Message Input</strong> – Users input the message to be hidden.</li><li><strong>Binary Conversion</strong> – Message is transformed into binary segments.</li><li><strong>AI Prompt Generation</strong> – Images are created using AI models for each binary segment.</li><li><strong>Feature Extraction (SURF + FrCHFM)</strong> – Features encode binary values into images.</li><li><strong>Stego Image Assembly &amp; Transfer</strong> – Encoded images are bundled and sent.</li><li><strong>Message Extraction at Receiver End</strong> – The receiver extracts the hidden message by regenerating image features.</li></ol><hr><h2 id="code-highlights" tabindex="-1">Code Highlights <a class="header-anchor" href="#code-highlights" aria-label="Permalink to &quot;Code Highlights&quot;">​</a></h2><h3 id="_1-surf-based-feature-extraction" tabindex="-1">1. SURF-Based Feature Extraction <a class="header-anchor" href="#_1-surf-based-feature-extraction" aria-label="Permalink to &quot;1. SURF-Based Feature Extraction&quot;">​</a></h3><p>One of the core components of our Generative Steganography System (GSIM) is the <strong>SURF-based feature extraction</strong>. This method enhances the system&#39;s resilience against geometric attacks by detecting keypoints robustly across different image scales. Below is a highlight of the <code>calculate_surf_descriptors</code> function, which is responsible for computing descriptors and generating binary sequences from image data.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># SURF feature extraction for keypoint detection and description</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> calculate_surf_descriptors</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(image, threshold</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, num_scales</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, grid_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, binary_threshold</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, num_top_keypoints</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    gray_image </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cv2.cvtColor(image, cv2.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">COLOR_BGR2GRAY</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    pyramid </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> build_image_pyramid(gray_image, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">num_scales</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">num_scales)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    all_keypoints </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> []</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Build the keypoints list from different scales</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scale_idx, scaled_image </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> enumerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(pyramid):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        scale_factor </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1.2</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> **</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scale_idx</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        integral_image </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> compute_integral_image(scaled_image)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        keypoints </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> detect_keypoints(integral_image, threshold, scaled_image, scale_factor)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # Append keypoints with scaled positions</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        all_keypoints.extend([(kp[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scale_factor, kp[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scale_factor, kp[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], scale_idx) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> kp </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> keypoints])</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Apply non-maximum suppression to filter keypoints</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    keypoints </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> non_max_suppression(all_keypoints, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">grid_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">grid_size)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Sort keypoints by the determinant (det) in descending order</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    sorted_keypoints </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> sorted</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(keypoints, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=lambda</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x: x[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">reverse</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Convert to OpenCV KeyPoint format for further processing</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    points2f </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.array([(k[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], k[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> k </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sorted_keypoints], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">np.float32)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    keypoints_cv2 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cv2.KeyPoint_convert(points2f, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Extract descriptors for refined keypoints</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    descriptors </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> extract_descriptors_parallel(keypoints_cv2, gray_image)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Generate binary sequence based on top descriptors and binary threshold</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    binary_sequence </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> generate_binary_sequence_from_descriptors(descriptors, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">threshold</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">binary_threshold)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> keypoints_cv2, descriptors, binary_sequence</span></span></code></pre></div>`,19)]))}const E=i(t,[["render",h]]);export{d as __pageData,E as default};
