import{_ as c,p as u,c as l,o as s,j as a,af as i,e as m,ag as n,t as g,C as f,ae as v,G as b,w as _}from"./chunks/framework.6g521mOR.js";const y={class:"riddle"},q={key:0},w={__name:"OverfitRiddle",setup(p){const t=u({q1:"",q2:"",q3:""}),o=u("");function r(){const h=t.value.q1.trim().toLowerCase(),e=t.value.q2.trim().toLowerCase(),d=t.value.q3.trim().toLowerCase();h==="yes"&&e==="yes"&&d==="no"?o.value=`🎉 You got it! 🎉

The model overfit to a single feature: the number of dots.
It learned to say YES only if there are exactly 3 dots — completely ignoring shape and color.

This is what happens when models learn correlations instead of meaning.`:o.value="❌ Not quite — keep trying! You might be overthinking it… or underthinking it 😉"}return(h,e)=>(s(),l("div",y,[e[3]||(e[3]=a("p",null,[a("strong",null,"blue triangle, 3 dots")],-1)),i(a("input",{"onUpdate:modelValue":e[0]||(e[0]=d=>t.value.q1=d),placeholder:"YES / NO / MAYBE"},null,512),[[n,t.value.q1]]),e[4]||(e[4]=a("p",null,[a("strong",null,"red square, 3 dots")],-1)),i(a("input",{"onUpdate:modelValue":e[1]||(e[1]=d=>t.value.q2=d),placeholder:"YES / NO / MAYBE"},null,512),[[n,t.value.q2]]),e[5]||(e[5]=a("p",null,[a("strong",null,"blue triangle, 2 dots")],-1)),i(a("input",{"onUpdate:modelValue":e[2]||(e[2]=d=>t.value.q3=d),placeholder:"YES / NO / MAYBE"},null,512),[[n,t.value.q3]]),a("button",{onClick:r},"Submit"),o.value?(s(),l("pre",q,g(o.value),1)):m("",!0)]))}},T=c(w,[["__scopeId","data-v-bdbf58be"]]),S=JSON.parse('{"title":"The Model Has Overfit","description":"Can you reverse-engineer this ML model’s logic?","frontmatter":{"title":"The Model Has Overfit","description":"Can you reverse-engineer this ML model’s logic?"},"headers":[],"relativePath":"overfit-riddle.md","filePath":"overfit-riddle.md"}'),C={name:"overfit-riddle.md"},O=Object.assign(C,{setup(p){return(t,o)=>{const r=f("ClientOnly");return s(),l("div",null,[o[0]||(o[0]=v(`<h1 id="🤖-the-model-has-overfit" tabindex="-1" data-v-b85048e5>🤖 The Model Has Overfit <a class="header-anchor" href="#🤖-the-model-has-overfit" aria-label="Permalink to &quot;🤖 The Model Has Overfit&quot;" data-v-b85048e5>​</a></h1><p data-v-b85048e5>You&#39;ve been handed a black-box ML model that was trained on a tiny dataset. It gives one of three outputs:</p><ul data-v-b85048e5><li data-v-b85048e5>✅ <strong data-v-b85048e5>YES</strong> (Confident match)</li><li data-v-b85048e5>❓ <strong data-v-b85048e5>MAYBE</strong> (Uncertain prediction)</li><li data-v-b85048e5>❌ <strong data-v-b85048e5>NO</strong> (Out of distribution)</li></ul><p data-v-b85048e5>But here&#39;s the thing... the model seems <em data-v-b85048e5>weird</em>. Maybe it’s learned the wrong thing?</p><hr data-v-b85048e5><h2 id="🧪-training-data" tabindex="-1" data-v-b85048e5>🧪 Training Data: <a class="header-anchor" href="#🧪-training-data" aria-label="Permalink to &quot;🧪 Training Data:&quot;" data-v-b85048e5>​</a></h2><table tabindex="0" data-v-b85048e5><thead data-v-b85048e5><tr data-v-b85048e5><th data-v-b85048e5>Input</th><th data-v-b85048e5>Output</th></tr></thead><tbody data-v-b85048e5><tr data-v-b85048e5><td data-v-b85048e5>red triangle, 3 dots</td><td data-v-b85048e5>✅ YES</td></tr><tr data-v-b85048e5><td data-v-b85048e5>blue square, 3 dots</td><td data-v-b85048e5>✅ YES</td></tr><tr data-v-b85048e5><td data-v-b85048e5>green circle, 3 dots</td><td data-v-b85048e5>✅ YES</td></tr><tr data-v-b85048e5><td data-v-b85048e5>red square, 2 dots</td><td data-v-b85048e5>❌ NO</td></tr><tr data-v-b85048e5><td data-v-b85048e5>green triangle, 4 dots</td><td data-v-b85048e5>❌ NO</td></tr></tbody></table><hr data-v-b85048e5><h2 id="🔍-predict-the-output" tabindex="-1" data-v-b85048e5>🔍 Predict the Output: <a class="header-anchor" href="#🔍-predict-the-output" aria-label="Permalink to &quot;🔍 Predict the Output:&quot;" data-v-b85048e5>​</a></h2><h2 id="try-to-figure-out-what-the-model-learned-choose-your-predictions-below" tabindex="-1" data-v-b85048e5>Try to figure out what the model learned! Choose your predictions below. <a class="header-anchor" href="#try-to-figure-out-what-the-model-learned-choose-your-predictions-below" aria-label="Permalink to &quot;Try to figure out what the model learned! Choose your predictions below.&quot;" data-v-b85048e5>​</a></h2><h2 id="the-model-has-overfitdescription-can-you-reverse-engineer-this-ml-model-s-logic" tabindex="-1" data-v-b85048e5>The Model Has Overfit description: Can you reverse-engineer this ML model’s logic? <a class="header-anchor" href="#the-model-has-overfitdescription-can-you-reverse-engineer-this-ml-model-s-logic" aria-label="Permalink to &quot;The Model Has Overfit
description: Can you reverse-engineer this ML model’s logic?&quot;" data-v-b85048e5>​</a></h2>`,11)),b(r,null,{default:_(()=>[b(T)]),_:1}),o[1]||(o[1]=v('<hr data-v-b85048e5><h3 id="💡-hint" tabindex="-1" data-v-b85048e5>💡 Hint: <a class="header-anchor" href="#💡-hint" aria-label="Permalink to &quot;💡 Hint:&quot;" data-v-b85048e5>​</a></h3><p data-v-b85048e5>Don’t overthink it… or do? 😉</p><hr data-v-b85048e5><h3 id="🧠-need-the-answer" tabindex="-1" data-v-b85048e5>🧠 Need the Answer? <a class="header-anchor" href="#🧠-need-the-answer" aria-label="Permalink to &quot;🧠 Need the Answer?&quot;" data-v-b85048e5>​</a></h3><details class="details custom-block" data-v-b85048e5><summary data-v-b85048e5>Click to reveal the model’s logic</summary><p data-v-b85048e5>The model overfit to a single feature: the number of dots.<br data-v-b85048e5> It learned to say YES only if there are exactly <strong data-v-b85048e5>3 dots</strong> — completely ignoring shape and color.</p><p data-v-b85048e5>This is what happens when models learn correlations instead of meaning.</p></details>',6))])}}}),x=c(O,[["__scopeId","data-v-b85048e5"]]);export{S as __pageData,x as default};
