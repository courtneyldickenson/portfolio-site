import{_ as i,c as a,o as n,ae as e}from"./chunks/framework.JvnCEULl.js";const t="/portfolio-site/assets/surf_images.CV4KsSJN.png",c=JSON.parse('{"title":"Generative Steganography System","description":"","frontmatter":{},"headers":[],"relativePath":"projects/GSIM.md","filePath":"projects/GSIM.md"}'),r={name:"projects/GSIM.md"};function l(h,s,p,k,o,g){return n(),a("div",null,s[0]||(s[0]=[e(`<hr><h1 id="generative-steganography-system" tabindex="-1">Generative Steganography System <a class="header-anchor" href="#generative-steganography-system" aria-label="Permalink to &quot;Generative Steganography System&quot;">​</a></h1><p><strong>Team Members:</strong> Ryan Farley, Courtney Dickenson, Ariel Ong, Tushar Wani<br><strong>Role:</strong> Feature Extraction, SURF Implementation, Parallel Processing<br><strong>Tools:</strong> Python, Google Colab, SDXL Turbo, OpenCV, Fractional Fourier Chebyshev Moments (FrCHFMs)<br><strong>Repository:</strong> <a href="https://github.com/R-D-Team-7/GSIM-Backend" target="_blank" rel="noreferrer">GitHub - GSIM-Backend</a></p><hr><h2 id="project-overview" tabindex="-1">Project Overview <a class="header-anchor" href="#project-overview" aria-label="Permalink to &quot;Project Overview&quot;">​</a></h2><p>This project explores <strong>coverless steganography</strong> – embedding secret messages in <strong>AI-generated images</strong> without modifying the carrier medium. By leveraging <strong>robust feature extraction</strong> methods like <strong>SURF descriptors</strong> and <strong>FrCHFMs</strong>, the system enhances resilience against <strong>geometric attacks</strong> (rotation, scaling, cropping).</p><h3 id="key-focus-areas" tabindex="-1">Key Focus Areas: <a class="header-anchor" href="#key-focus-areas" aria-label="Permalink to &quot;Key Focus Areas:&quot;">​</a></h3><ul><li><strong>AI-Generated Image Steganography</strong> – No alterations to the image, ensuring covert communication.</li><li><strong>Geometric Attack Resistance</strong> – Secure against transformations that typically break traditional steganography.</li><li><strong>High-Capacity Encoding</strong> – Messages up to <strong>576 bits</strong> concealed efficiently across image sets.</li></ul><hr><h2 id="key-contributions" tabindex="-1">Key Contributions <a class="header-anchor" href="#key-contributions" aria-label="Permalink to &quot;Key Contributions&quot;">​</a></h2><ul><li><strong>Engineered a complete steganography pipeline</strong> to encode and extract messages seamlessly.</li><li><strong>Implemented SURF-based feature extraction</strong> to withstand geometric transformations.</li><li><strong>Optimized for speed</strong> by parallelizing keypoint detection with Python&#39;s <code>ThreadPoolExecutor</code>.</li><li><strong>Developed amplitude mapping algorithms</strong> for encoding binary sequences into generated images.</li></ul><hr><h2 id="system-architecture" tabindex="-1">System Architecture <a class="header-anchor" href="#system-architecture" aria-label="Permalink to &quot;System Architecture&quot;">​</a></h2><p><strong>Workflow Breakdown:</strong></p><ol><li><strong>Secret Message Input</strong> – Users input the message to be hidden.</li><li><strong>Binary Conversion</strong> – Message is transformed into binary segments.</li><li><strong>AI Prompt Generation</strong> – Images are created using AI models for each binary segment.</li><li><strong>Feature Extraction (SURF + FrCHFM)</strong> – Features encode binary values into images.</li><li><strong>Stego Image Assembly &amp; Transfer</strong> – Encoded images are bundled and sent.</li><li><strong>Message Extraction at Receiver End</strong> – The receiver extracts the hidden message by regenerating image features.</li></ol><hr><h2 id="code-highlights" tabindex="-1">Code Highlights <a class="header-anchor" href="#code-highlights" aria-label="Permalink to &quot;Code Highlights&quot;">​</a></h2><h3 id="_1-surf-based-feature-extraction" tabindex="-1">1. SURF-Based Feature Extraction <a class="header-anchor" href="#_1-surf-based-feature-extraction" aria-label="Permalink to &quot;1. SURF-Based Feature Extraction&quot;">​</a></h3><p>One of the core components of our Generative Steganography System (GSIM) is the <strong>SURF-based feature extraction</strong>. This method enhances the system&#39;s resilience against geometric attacks by detecting keypoints robustly across different image scales. Below is a highlight of the <code>calculate_surf_descriptors</code> function, which is responsible for computing descriptors and generating binary sequences from image data.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># SURF feature extraction for keypoint detection and description</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> calculate_surf_descriptors</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(image, threshold</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, num_scales</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, grid_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, binary_threshold</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, num_top_keypoints</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    gray_image </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cv2.cvtColor(image, cv2.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">COLOR_BGR2GRAY</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    pyramid </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> build_image_pyramid(gray_image, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">num_scales</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">num_scales)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    all_keypoints </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> []</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Build the keypoints list from different scales</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scale_idx, scaled_image </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> enumerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(pyramid):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        scale_factor </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1.2</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> **</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scale_idx</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        integral_image </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> compute_integral_image(scaled_image)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        keypoints </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> detect_keypoints(integral_image, threshold, scaled_image, scale_factor)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # Append keypoints with scaled positions</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        all_keypoints.extend([(kp[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scale_factor, kp[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scale_factor, kp[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], scale_idx) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> kp </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> keypoints])</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Apply non-maximum suppression to filter keypoints</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    keypoints </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> non_max_suppression(all_keypoints, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">grid_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">grid_size)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Sort keypoints by the determinant (det) in descending order</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    sorted_keypoints </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> sorted</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(keypoints, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=lambda</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x: x[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">reverse</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Convert to OpenCV KeyPoint format for further processing</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    points2f </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.array([(k[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], k[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> k </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sorted_keypoints], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">np.float32)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    keypoints_cv2 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cv2.KeyPoint_convert(points2f, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Extract descriptors for refined keypoints</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    descriptors </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> extract_descriptors_parallel(keypoints_cv2, gray_image)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Generate binary sequence based on top descriptors and binary threshold</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    binary_sequence </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> generate_binary_sequence_from_descriptors(descriptors, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">threshold</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">binary_threshold)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> keypoints_cv2, descriptors, binary_sequence</span></span></code></pre></div><p><strong>Key Benefits:</strong></p><ul><li><strong>Robust against transformations</strong> – Scaling, rotation, and slight cropping.</li><li><strong>Parallelized execution</strong> – Faster processing for large datasets.</li></ul><p><img src="`+t+`" alt="Banner Image"></p><hr><h3 id="_2-fractional-fourier-chebyshev-moments-frchfms" tabindex="-1">2. Fractional Fourier Chebyshev Moments (FrCHFMs) <a class="header-anchor" href="#_2-fractional-fourier-chebyshev-moments-frchfms" aria-label="Permalink to &quot;2. Fractional Fourier Chebyshev Moments (FrCHFMs)&quot;">​</a></h3><p>To enhance the system’s robustness against geometric distortions, we utilize <strong>Fractional Chebyshev-Fourier Moments (FrCHFMs)</strong>, computed efficiently on the GPU. This method leverages radial basis functions and Fourier transforms in polar coordinates to ensure invariance under transformations like scaling and rotation. Below is a highlight of the GPU-accelerated FrCHFM computation function.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> compute_frchfm_gpu</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(image, max_degree, t):</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    Compute Fractional Chebyshev-Fourier moments (FrCHFMs) of an input image on the GPU.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    Parameters:</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        image (2D numpy array): Grayscale image.</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        max_degree (int): Maximum degree of the Chebyshev polynomial.</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        t (float): Fractional parameter.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    Returns:</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        frchfm (2D numpy array): The computed Fractional Chebyshev-Fourier moments.</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Convert image to polar coordinates and then transfer to GPU</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    polar_image, r, theta </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> convert_to_polar(image)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    polar_image_gpu </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cp.array(polar_image)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    r_gpu </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cp.array(r)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    theta_gpu </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cp.array(theta)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Fourier transform in angular direction (theta), shifted and moved to GPU</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    F_image </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cp.fft.fftshift(cp.fft.fft2(polar_image_gpu))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Initialize an array on GPU to store the FrCHFMs</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    frchfm_gpu </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cp.zeros((max_degree </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> *</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> max_degree </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">cp.complex128)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Precompute angular components on GPU</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    m_values </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cp.arange(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">max_degree, max_degree </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    angular_components </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cp.exp(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">j</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> *</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> m_values[:, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> theta_gpu)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> n </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(max_degree </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # Compute radial basis function for each degree</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        Rtn_gpu </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> radial_basis_function_gpu(n, t, r_gpu)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # Compute FrCHFMs for each value of m in a vectorized way</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        frchfm_gpu[n, :] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cp.sum(F_image </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Rtn_gpu </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> angular_components </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> r_gpu, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">axis</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Transfer result back to CPU</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cp.asnumpy(frchfm_gpu)</span></span></code></pre></div><p><strong>Key Benefits:</strong></p><ul><li><strong>Geometric invariance</strong> – Maintains stability across distortions.</li><li><strong>Polar coordinate mapping</strong> – Improves feature localization and precision.</li></ul><hr><h3 id="_3-message-encoding-ai-prompt-mapping" tabindex="-1">3. Message Encoding &amp; AI Prompt Mapping <a class="header-anchor" href="#_3-message-encoding-ai-prompt-mapping" aria-label="Permalink to &quot;3. Message Encoding &amp; AI Prompt Mapping&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Encoding message bits using AI prompt-to-image mapping</span></span></code></pre></div><p><strong>Key Benefits:</strong></p><ul><li><strong>Dynamic prompt mapping</strong> – Converts binary segments into distinct image features.</li><li><strong>SDXL Turbo Integration</strong> – High-quality AI-generated images for encoding.</li></ul><hr><h2 id="results" tabindex="-1">Results <a class="header-anchor" href="#results" aria-label="Permalink to &quot;Results&quot;">​</a></h2><ul><li><strong>PSNR:</strong> &gt; 38 dB – Ensuring nearly indistinguishable stego images.</li><li><strong>Extraction Accuracy:</strong> 100% across all test cases.</li><li><strong>Encoding Capacity:</strong> 8 bits per image, supporting 576 bits using 72 images.</li></ul><hr><h2 id="challenges-and-solutions" tabindex="-1">Challenges and Solutions <a class="header-anchor" href="#challenges-and-solutions" aria-label="Permalink to &quot;Challenges and Solutions&quot;">​</a></h2><h3 id="_1-keypoint-detection-instability" tabindex="-1">1. Keypoint Detection Instability <a class="header-anchor" href="#_1-keypoint-detection-instability" aria-label="Permalink to &quot;1. Keypoint Detection Instability&quot;">​</a></h3><p><strong>Challenge:</strong> Keypoints were inconsistently detected across transformed images, affecting extraction accuracy.<br><strong>Solution:</strong> Applied <strong>non-maximum suppression tuning</strong> and optimized <strong>SURF descriptor thresholds</strong> to enhance detection stability.</p><h3 id="_2-computational-overhead" tabindex="-1">2. Computational Overhead <a class="header-anchor" href="#_2-computational-overhead" aria-label="Permalink to &quot;2. Computational Overhead&quot;">​</a></h3><p><strong>Challenge:</strong> Image generation and feature extraction introduced significant processing delays.<br><strong>Solution:</strong> Implemented <strong>parallel processing</strong> using Python’s <code>ThreadPoolExecutor</code>, reducing runtime by up to 40%.</p><h3 id="_3-feature-drift-during-cropping" tabindex="-1">3. Feature Drift During Cropping <a class="header-anchor" href="#_3-feature-drift-during-cropping" aria-label="Permalink to &quot;3. Feature Drift During Cropping&quot;">​</a></h3><p><strong>Challenge:</strong> Cropping led to feature misalignment, causing message extraction errors.<br><strong>Solution:</strong> Incorporated <strong>FrCHFM amplitude mapping</strong>, ensuring geometric invariance and preserving key features post-cropping.</p><hr><h2 id="future-enhancements" tabindex="-1">Future Enhancements <a class="header-anchor" href="#future-enhancements" aria-label="Permalink to &quot;Future Enhancements&quot;">​</a></h2><ul><li><strong>Automated parameter tuning</strong> for varying message sizes.</li><li><strong>Receiver simulation</strong> for end-to-end testing.</li><li><strong>Encrypted CLI messaging</strong> for secure peer-to-peer communication.</li></ul><hr><h2 id="key-takeaways" tabindex="-1">Key Takeaways <a class="header-anchor" href="#key-takeaways" aria-label="Permalink to &quot;Key Takeaways&quot;">​</a></h2><ul><li><strong>Innovative coverless steganography</strong> using AI-generated images and feature extraction.</li><li><strong>High resilience to geometric attacks</strong> – A leap forward in secure data embedding.</li><li><strong>Open-source commitment</strong> – Encouraging community collaboration and growth in steganography research.</li></ul><hr>`,52)]))}const E=i(r,[["render",l]]);export{c as __pageData,E as default};
