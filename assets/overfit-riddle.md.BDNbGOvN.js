import{_ as p,p as h,c as l,o as c,j as a,af as i,e as g,ag as n,t as f,C as b,ae as u,G as v,w as _}from"./chunks/framework.JvnCEULl.js";const y={class:"riddle"},q={key:0},w={__name:"OverfitRiddle",setup(m){const t=h({q1:"",q2:"",q3:""}),o=h("");function r(){const s=t.value.q1.trim().toLowerCase(),e=t.value.q2.trim().toLowerCase(),d=t.value.q3.trim().toLowerCase();s==="yes"&&e==="yes"&&d==="no"?o.value=`🎉 You got it! 🎉

The model overfit to a single feature: the number of dots.
It learned to say YES only if there are exactly 3 dots — completely ignoring shape and color.

This is what happens when models learn correlations instead of meaning.`:o.value="❌ Not quite — keep trying! You might be overthinking it… or underthinking it 😉"}return(s,e)=>(c(),l("div",y,[e[3]||(e[3]=a("p",null,[a("strong",null,"blue triangle, 3 dots")],-1)),i(a("input",{"onUpdate:modelValue":e[0]||(e[0]=d=>t.value.q1=d),placeholder:"YES / NO / MAYBE"},null,512),[[n,t.value.q1]]),e[4]||(e[4]=a("p",null,[a("strong",null,"red square, 3 dots")],-1)),i(a("input",{"onUpdate:modelValue":e[1]||(e[1]=d=>t.value.q2=d),placeholder:"YES / NO / MAYBE"},null,512),[[n,t.value.q2]]),e[5]||(e[5]=a("p",null,[a("strong",null,"blue triangle, 2 dots")],-1)),i(a("input",{"onUpdate:modelValue":e[2]||(e[2]=d=>t.value.q3=d),placeholder:"YES / NO / MAYBE"},null,512),[[n,t.value.q3]]),a("button",{onClick:r},"Submit"),o.value?(c(),l("pre",q,f(o.value),1)):g("",!0)]))}},T=p(w,[["__scopeId","data-v-bdbf58be"]]),S=JSON.parse('{"title":"The Model Has Overfit","description":"Can you reverse-engineer this ML model’s logic?","frontmatter":{"title":"The Model Has Overfit","description":"Can you reverse-engineer this ML model’s logic?"},"headers":[],"relativePath":"overfit-riddle.md","filePath":"overfit-riddle.md"}'),C={name:"overfit-riddle.md"},O=Object.assign(C,{setup(m){return(t,o)=>{const r=b("ClientOnly");return c(),l("div",null,[o[0]||(o[0]=u(`<h1 id="🤖-the-model-has-overfit" tabindex="-1" data-v-c578c793>🤖 The Model Has Overfit <a class="header-anchor" href="#🤖-the-model-has-overfit" aria-label="Permalink to &quot;🤖 The Model Has Overfit&quot;" data-v-c578c793>​</a></h1><p data-v-c578c793>You&#39;ve been handed a black-box ML model that was trained on a tiny dataset. It gives one of three outputs:</p><ul data-v-c578c793><li data-v-c578c793>✅ <strong data-v-c578c793>YES</strong> (Confident match)</li><li data-v-c578c793>❓ <strong data-v-c578c793>MAYBE</strong> (Uncertain prediction)</li><li data-v-c578c793>❌ <strong data-v-c578c793>NO</strong> (Out of distribution)</li></ul><p data-v-c578c793>But here&#39;s the thing... the model seems <em data-v-c578c793>weird</em>. Maybe it’s learned the wrong thing?</p><hr data-v-c578c793><h2 id="🧪-training-data" tabindex="-1" data-v-c578c793>🧪 Training Data: <a class="header-anchor" href="#🧪-training-data" aria-label="Permalink to &quot;🧪 Training Data:&quot;" data-v-c578c793>​</a></h2><table tabindex="0" data-v-c578c793><thead data-v-c578c793><tr data-v-c578c793><th data-v-c578c793>Input</th><th data-v-c578c793>Output</th></tr></thead><tbody data-v-c578c793><tr data-v-c578c793><td data-v-c578c793>red triangle, 3 dots</td><td data-v-c578c793>✅ YES</td></tr><tr data-v-c578c793><td data-v-c578c793>blue square, 3 dots</td><td data-v-c578c793>✅ YES</td></tr><tr data-v-c578c793><td data-v-c578c793>green circle, 3 dots</td><td data-v-c578c793>✅ YES</td></tr><tr data-v-c578c793><td data-v-c578c793>red square, 2 dots</td><td data-v-c578c793>❌ NO</td></tr><tr data-v-c578c793><td data-v-c578c793>green triangle, 4 dots</td><td data-v-c578c793>❌ NO</td></tr></tbody></table><hr data-v-c578c793><h2 id="🔍-predict-the-output" tabindex="-1" data-v-c578c793>🔍 Predict the Output: <a class="header-anchor" href="#🔍-predict-the-output" aria-label="Permalink to &quot;🔍 Predict the Output:&quot;" data-v-c578c793>​</a></h2><h2 id="try-to-figure-out-what-the-model-learned-choose-your-predictions-below" tabindex="-1" data-v-c578c793>Try to figure out what the model learned! Choose your predictions below. <a class="header-anchor" href="#try-to-figure-out-what-the-model-learned-choose-your-predictions-below" aria-label="Permalink to &quot;Try to figure out what the model learned! Choose your predictions below.&quot;" data-v-c578c793>​</a></h2><h2 id="title-the-model-has-overfitdescription-can-you-reverse-engineer-this-ml-model-s-logic" tabindex="-1" data-v-c578c793>title: The Model Has Overfit description: Can you reverse-engineer this ML model’s logic? <a class="header-anchor" href="#title-the-model-has-overfitdescription-can-you-reverse-engineer-this-ml-model-s-logic" aria-label="Permalink to &quot;title: The Model Has Overfit
description: Can you reverse-engineer this ML model’s logic?&quot;" data-v-c578c793>​</a></h2>`,11)),v(r,null,{default:_(()=>[v(T)]),_:1}),o[1]||(o[1]=u('<hr data-v-c578c793><h3 id="💡-hint" tabindex="-1" data-v-c578c793>💡 Hint: <a class="header-anchor" href="#💡-hint" aria-label="Permalink to &quot;💡 Hint:&quot;" data-v-c578c793>​</a></h3><p data-v-c578c793>Don’t overthink it… or do? 😉</p><hr data-v-c578c793><h3 id="🧠-need-the-answer" tabindex="-1" data-v-c578c793>🧠 Need the Answer? <a class="header-anchor" href="#🧠-need-the-answer" aria-label="Permalink to &quot;🧠 Need the Answer?&quot;" data-v-c578c793>​</a></h3><details class="details custom-block" data-v-c578c793><summary data-v-c578c793>Click to reveal the model’s logic</summary><p data-v-c578c793>The model overfit to a single feature: the number of dots.<br data-v-c578c793> It learned to say YES only if there are exactly <strong data-v-c578c793>3 dots</strong> — completely ignoring shape and color.</p><p data-v-c578c793>This is what happens when models learn correlations instead of meaning.</p></details>',6))])}}}),x=p(O,[["__scopeId","data-v-c578c793"]]);export{S as __pageData,x as default};
