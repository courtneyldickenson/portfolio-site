import{_ as s,c as a,o as e,ae as n}from"./chunks/framework.6g521mOR.js";const E=JSON.parse('{"title":"LEGO Classifier on Raspberry Pi","description":"","frontmatter":{"sidebar":false},"headers":[],"relativePath":"projects/Lego_classifier.md","filePath":"projects/Lego_classifier.md"}'),t={name:"projects/Lego_classifier.md"};function l(h,i,r,p,k,o){return e(),a("div",null,i[0]||(i[0]=[n(`<h1 id="lego-classifier-on-raspberry-pi" tabindex="-1">LEGO Classifier on Raspberry Pi <a class="header-anchor" href="#lego-classifier-on-raspberry-pi" aria-label="Permalink to &quot;LEGO Classifier on Raspberry Pi&quot;">​</a></h1><p><strong>Role:</strong> Developer, Hardware Integrator, ML Pipeline Designer<br><strong>Tools:</strong> Raspberry Pi 5, TensorFlow Lite, OpenCV, Keras, Python<br><strong>Repository:</strong> <em>(private/local only – model was exported and deployed directly)</em></p><hr><h2 id="project-overview" tabindex="-1">Project Overview <a class="header-anchor" href="#project-overview" aria-label="Permalink to &quot;Project Overview&quot;">​</a></h2><p>This project uses a Raspberry Pi and TensorFlow Lite to classify LEGO pieces in real time using a mounted camera and a custom-trained model. The setup includes a conveyor belt system to move parts beneath the Pi Camera, with predictions rendered locally on-device. It’s a proof-of-concept for hardware-efficient, camera-based part recognition — with applications in toy sorting, inventory tracking, and hobbyist projects.</p><h3 id="key-focus-areas" tabindex="-1">Key Focus Areas: <a class="header-anchor" href="#key-focus-areas" aria-label="Permalink to &quot;Key Focus Areas:&quot;">​</a></h3><ul><li><strong>On-device ML</strong> – Model runs directly on the Pi using TFLite, no internet or cloud inference.</li><li><strong>Custom LEGO Dataset</strong> – Trained using real-life images and part labels pulled via the Rebrickable API.</li><li><strong>Hardware Integration</strong> – Uses Pi Camera and GPIO-friendly layout for testing with physical parts.</li></ul><hr><h2 id="key-contributions" tabindex="-1">Key Contributions <a class="header-anchor" href="#key-contributions" aria-label="Permalink to &quot;Key Contributions&quot;">​</a></h2><ul><li><strong>Built a real-time image classification pipeline</strong> optimized for Raspberry Pi using TensorFlow Lite.</li><li><strong>Collected, cleaned, and labeled training data</strong> using a mix of Rebrickable metadata and live Pi Camera captures.</li><li><strong>Designed preprocessing logic</strong> to normalize lighting, resize inputs, and convert labels to one-hot vectors.</li><li><strong>Wrote inference script</strong> using TFLite runtime for fast predictions on embedded hardware.</li></ul><hr><h2 id="system-architecture" tabindex="-1">System Architecture <a class="header-anchor" href="#system-architecture" aria-label="Permalink to &quot;System Architecture&quot;">​</a></h2><h3 id="workflow-breakdown" tabindex="-1">Workflow Breakdown: <a class="header-anchor" href="#workflow-breakdown" aria-label="Permalink to &quot;Workflow Breakdown:&quot;">​</a></h3><ol><li><strong>Data Collection</strong> – Captured 128×128px images of LEGO parts and associated each with a part number.</li><li><strong>Model Training</strong> – Trained a CNN using Keras, then converted it to TFLite for edge deployment.</li><li><strong>Real-Time Inference</strong> – Camera feed is streamed, cropped, resized, and classified every 0.5s.</li><li><strong>Prediction Display</strong> – Predicted part number is printed in terminal or optionally shown on-screen.</li></ol><hr><h2 id="code-highlights" tabindex="-1">Code Highlights <a class="header-anchor" href="#code-highlights" aria-label="Permalink to &quot;Code Highlights&quot;">​</a></h2><h3 id="_1-training-the-model-with-keras" tabindex="-1">1. Training the Model with Keras <a class="header-anchor" href="#_1-training-the-model-with-keras" aria-label="Permalink to &quot;1. Training the Model with Keras&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Sequential([</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    Conv2D(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">32</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">input_shape</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">128</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">128</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    MaxPooling2D(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    Conv2D(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">64</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    MaxPooling2D(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    Flatten(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">128</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    Dense(num_classes, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;softmax&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model.compile(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">optimizer</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;adam&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">loss</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;categorical_crossentropy&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">metrics</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;accuracy&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model.fit(train_generator, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">validation_data</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">val_generator, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">epochs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><h3 id="_2-converting-to-tensorflow-lite" tabindex="-1">2. Converting to TensorFlow Lite <a class="header-anchor" href="#_2-converting-to-tensorflow-lite" aria-label="Permalink to &quot;2. Converting to TensorFlow Lite&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">converter </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tf.lite.TFLiteConverter.from_keras_model(model)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tflite_model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> converter.convert()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> open</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;lego_model.tflite&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;wb&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> f:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    f.write(tflite_model)</span></span></code></pre></div><h3 id="_3-real-time-inference-on-raspberry-pi" tabindex="-1">3. Real-Time Inference on Raspberry Pi <a class="header-anchor" href="#_3-real-time-inference-on-raspberry-pi" aria-label="Permalink to &quot;3. Real-Time Inference on Raspberry Pi&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cv2</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tflite_runtime.interpreter </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tflite</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> numpy </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">interpreter </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tflite.Interpreter(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">model_path</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;lego_model.tflite&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">interpreter.allocate_tensors()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">input_details </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> interpreter.get_input_details()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">output_details </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> interpreter.get_output_details()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">cap </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cv2.VideoCapture(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">while</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ret, frame </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cap.read()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    img </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cv2.resize(frame, (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">128</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">128</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    img </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> img.astype(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;float32&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 255.0</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    img </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.expand_dims(img, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">axis</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    interpreter.set_tensor(input_details[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;index&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], img)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    interpreter.invoke()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    prediction </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> interpreter.get_tensor(output_details[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;index&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    predicted_class </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.argmax(prediction)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Predicted LEGO part: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">predicted_class</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><hr><h2 id="results" tabindex="-1">Results <a class="header-anchor" href="#results" aria-label="Permalink to &quot;Results&quot;">​</a></h2><ul><li><strong>Prediction Accuracy:</strong> ~87% test accuracy on common LEGO part types</li><li><strong>Inference Speed:</strong> ~10 FPS on Pi 5 (optimized with image resizing + simple CNN)</li><li><strong>Deployment:</strong> Fully functional offline, no external dependencies during runtime</li></ul><hr><h2 id="challenges-and-solutions" tabindex="-1">Challenges and Solutions <a class="header-anchor" href="#challenges-and-solutions" aria-label="Permalink to &quot;Challenges and Solutions&quot;">​</a></h2><h3 id="_1-lighting-variability" tabindex="-1">1. Lighting Variability <a class="header-anchor" href="#_1-lighting-variability" aria-label="Permalink to &quot;1. Lighting Variability&quot;">​</a></h3><ul><li><strong>Issue:</strong> Prediction confidence dropped in low lighting.</li><li><strong>Fix:</strong> Added histogram equalization and discarded poor-quality training images.</li></ul><h3 id="_2-model-size-vs-accuracy" tabindex="-1">2. Model Size vs. Accuracy <a class="header-anchor" href="#_2-model-size-vs-accuracy" aria-label="Permalink to &quot;2. Model Size vs. Accuracy&quot;">​</a></h3><ul><li><strong>Issue:</strong> Large models were too slow on the Pi.</li><li><strong>Fix:</strong> Used a minimal CNN and quantized the model to reduce inference cost.</li></ul><h3 id="_3-dataset-noise" tabindex="-1">3. Dataset Noise <a class="header-anchor" href="#_3-dataset-noise" aria-label="Permalink to &quot;3. Dataset Noise&quot;">​</a></h3><ul><li><strong>Issue:</strong> Incorrect labels from automation pipeline.</li><li><strong>Fix:</strong> Manually cleaned CSV label mappings and added test-time sanity checks.</li></ul><hr><h2 id="future-enhancements" tabindex="-1">Future Enhancements <a class="header-anchor" href="#future-enhancements" aria-label="Permalink to &quot;Future Enhancements&quot;">​</a></h2><ul><li>Add a touch screen interface for live display and override options.</li><li>Automate training with label validation and new part intake.</li><li>Publish to GitHub with open dataset export support.</li></ul><hr><h2 id="key-takeaways" tabindex="-1">Key Takeaways <a class="header-anchor" href="#key-takeaways" aria-label="Permalink to &quot;Key Takeaways&quot;">​</a></h2><ul><li>Embedded ML can work incredibly well — even on low-power hardware.</li><li>Real-world image data is messy but more meaningful than synthetic datasets.</li><li>Tiny projects like this can spark <strong>unexpectedly big ideas</strong> in automation and robotics.</li></ul><hr>`,40)]))}const g=s(t,[["render",l]]);export{E as __pageData,g as default};
